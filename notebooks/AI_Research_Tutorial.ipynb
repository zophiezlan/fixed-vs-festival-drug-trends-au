{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Drug Checking Services Analysis\n",
    "\n",
    "## Comprehensive Tutorial: Fixed-Site vs Festival Services in Australia\n",
    "\n",
    "This notebook demonstrates the full AI-driven research pipeline including:\n",
    "- Quantitative analysis with advanced statistics\n",
    "- AI-powered qualitative analysis (NLP)\n",
    "- Machine learning predictions\n",
    "- Network analysis\n",
    "- Policy recommendations\n",
    "\n",
    "**Author:** AI Research Team  \n",
    "**Date:** 2024-2025  \n",
    "**Version:** 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Import our modules\n",
    "from analysis import DrugCheckingAnalyzer\n",
    "from qualitative_analysis import QualitativeAnalyzer\n",
    "from ai_nlp_analysis import AIQualitativeAnalyzer\n",
    "from ml_predictive_models import NPSTrendPredictor, AnomalyDetector, SubstanceClusterAnalyzer\n",
    "from ai_research_assistant import ResearchAssistant\n",
    "from network_analysis import SubstanceNetworkAnalyzer\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "\n",
    "First, let's generate our datasets (or load existing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data if not already present\n",
    "from generate_data import main as generate_quant_data\n",
    "from generate_qualitative_data import main as generate_qual_data\n",
    "\n",
    "print(\"Generating datasets...\")\n",
    "generate_quant_data()\n",
    "generate_qual_data()\n",
    "print(\"âœ“ Data generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quantitative data\n",
    "quant_df = pd.read_csv('../data/combined_data.csv')\n",
    "quant_df['date'] = pd.to_datetime(quant_df['date'])\n",
    "\n",
    "print(f\"Quantitative Data: {len(quant_df)} samples\")\n",
    "print(f\"Service Types: {quant_df['service_type'].unique()}\")\n",
    "print(f\"Date Range: {quant_df['date'].min()} to {quant_df['date'].max()}\")\n",
    "print(f\"Unique Substances: {quant_df['substance_detected'].nunique()}\")\n",
    "\n",
    "quant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load qualitative data\n",
    "qual_df = pd.read_csv('../data/all_interviews.csv')\n",
    "qual_df['interview_date'] = pd.to_datetime(qual_df['interview_date'])\n",
    "\n",
    "print(f\"Qualitative Data: {len(qual_df)} interviews\")\n",
    "print(f\"Participant Types: {qual_df['participant_type'].unique()}\")\n",
    "print(f\"Service Types: {qual_df['service_type'].unique()}\")\n",
    "\n",
    "qual_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantitative Analysis\n",
    "\n",
    "### 3.1 Basic Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = DrugCheckingAnalyzer(dataframe=quant_df)\n",
    "\n",
    "# Get service comparison\n",
    "comparison = analyzer.get_service_comparison()\n",
    "\n",
    "# Display as DataFrame for better visualization\n",
    "comparison_df = pd.DataFrame(comparison).T\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Diversity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate diversity indices\n",
    "diversity_results = {}\n",
    "for service_type in quant_df['service_type'].unique():\n",
    "    diversity_results[service_type] = analyzer.calculate_diversity_index(service_type)\n",
    "\n",
    "diversity_df = pd.DataFrame(diversity_results).T\n",
    "print(\"Diversity Indices by Service Type:\")\n",
    "print(diversity_df)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Shannon Diversity\n",
    "diversity_df['shannon_diversity'].plot(kind='bar', ax=axes[0], color=['#1f77b4', '#ff7f0e'])\n",
    "axes[0].set_title('Shannon Diversity Index', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Index Value')\n",
    "\n",
    "# Simpson Diversity\n",
    "diversity_df['simpson_diversity'].plot(kind='bar', ax=axes[1], color=['#1f77b4', '#ff7f0e'])\n",
    "axes[1].set_title('Simpson Diversity Index', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Index Value')\n",
    "\n",
    "# Species Richness\n",
    "diversity_df['species_richness'].plot(kind='bar', ax=axes[2], color=['#1f77b4', '#ff7f0e'])\n",
    "axes[2].set_title('Species Richness', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Unique Substances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AI-Powered NLP Analysis\n",
    "\n",
    "### 4.1 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_analyzer = AIQualitativeAnalyzer(dataframe=qual_df)\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiment_results = ai_analyzer.perform_sentiment_analysis()\n",
    "\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "for service_type, data in sentiment_results.get('by_service_type', {}).items():\n",
    "    print(f\"\\n{service_type}:\")\n",
    "    print(f\"  Average Sentiment: {data.get('avg_sentiment', 0):.3f}\")\n",
    "    print(f\"  Positive Responses: {data.get('positive_responses', 0)}\")\n",
    "    print(f\"  Negative Responses: {data.get('negative_responses', 0)}\")\n",
    "    print(f\"  Neutral Responses: {data.get('neutral_responses', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform topic modeling\n",
    "topic_results = ai_analyzer.perform_topic_modeling(n_topics=5, method='lda')\n",
    "\n",
    "if 'topics' in topic_results and 'error' not in topic_results:\n",
    "    print(\"Discovered Topics:\\n\")\n",
    "    for topic_name, topic_data in topic_results['topics'].items():\n",
    "        print(f\"{topic_name}:\")\n",
    "        print(f\"  Keywords: {', '.join(topic_data['keywords'][:8])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ai_analyzer.extract_named_entities()\n",
    "\n",
    "print(\"Most Mentioned Substances:\")\n",
    "for substance, count in list(entities['substances'].items())[:10]:\n",
    "    print(f\"  {substance}: {count}\")\n",
    "\n",
    "print(\"\\nService Type Mentions:\")\n",
    "for service, count in entities['service_types'].items():\n",
    "    print(f\"  {service}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Predictions\n",
    "\n",
    "### 5.1 NPS Trend Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = NPSTrendPredictor(dataframe=quant_df)\n",
    "\n",
    "# Forecast for both service types\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for idx, service_type in enumerate(['Fixed-site', 'Festival']):\n",
    "    if service_type in quant_df['service_type'].unique():\n",
    "        forecast = predictor.forecast_nps_trend(service_type, periods_ahead=6)\n",
    "        \n",
    "        if 'error' not in forecast:\n",
    "            # Plot predictions\n",
    "            periods = list(range(1, len(forecast['predictions']) + 1))\n",
    "            axes[idx].plot(periods, forecast['predictions'], 'o-', label='Forecast', linewidth=2)\n",
    "            \n",
    "            if 'lower_bound' in forecast:\n",
    "                axes[idx].fill_between(periods, forecast['lower_bound'], \n",
    "                                     forecast['upper_bound'], alpha=0.3, label='95% CI')\n",
    "            \n",
    "            axes[idx].axhline(y=forecast['current_rate'], color='r', \n",
    "                            linestyle='--', label='Current Rate')\n",
    "            axes[idx].set_title(f'{service_type} NPS Forecast', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_xlabel('Periods Ahead')\n",
    "            axes[idx].set_ylabel('NPS Detection Rate')\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "            \n",
    "            print(f\"{service_type} Forecast:\")\n",
    "            print(f\"  Current Rate: {forecast['current_rate']:.1%}\")\n",
    "            print(f\"  Predicted Trend: {forecast['trend'].upper()}\")\n",
    "            print(f\"  6-Period Forecast: {forecast['predictions'][-1]:.1%}\\n\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector = AnomalyDetector(dataframe=quant_df)\n",
    "\n",
    "# Detect emerging substances\n",
    "emerging = anomaly_detector.detect_emerging_substances(threshold_days=30)\n",
    "\n",
    "print(\"ðŸš¨ Emerging Substances (Last 30 Days):\\n\")\n",
    "for service_type, data in emerging.items():\n",
    "    print(f\"{service_type}: {data['emerging_count']} new substances\")\n",
    "    for sub in data['substances'][:5]:\n",
    "        print(f\"  - {sub['substance']} (NPS: {sub['is_nps']}) - First detected: {sub['first_detected']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Substance Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_analyzer = SubstanceClusterAnalyzer(dataframe=quant_df)\n",
    "clusters = cluster_analyzer.cluster_by_detection_patterns(n_clusters=4)\n",
    "\n",
    "if 'error' not in clusters:\n",
    "    print(\"Substance Clusters:\\n\")\n",
    "    for cluster_name, data in clusters.items():\n",
    "        print(f\"{cluster_name} ({data['count']} substances):\")\n",
    "        print(f\"  NPS %: {data['characteristics']['nps_percentage']:.1f}%\")\n",
    "        print(f\"  Fixed-site %: {data['characteristics']['fixed_site_percentage']:.1f}%\")\n",
    "        print(f\"  Substances: {', '.join(data['substances'][:5])}\")\n",
    "        if len(data['substances']) > 5:\n",
    "            print(f\"  ... and {len(data['substances']) - 5} more\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Network Analysis\n",
    "\n",
    "### 6.1 Substance Co-occurrence Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_analyzer = SubstanceNetworkAnalyzer(dataframe=quant_df)\n",
    "networks = network_analyzer.build_temporal_cooccurrence_network(time_window='W', min_cooccurrence=2)\n",
    "\n",
    "print(\"Co-occurrence Network Analysis:\\n\")\n",
    "for service_type, data in networks.items():\n",
    "    if 'error' not in data:\n",
    "        print(f\"{service_type}:\")\n",
    "        if 'nodes' in data:\n",
    "            print(f\"  Network Size: {data['nodes']} substances, {data['edges']} connections\")\n",
    "            print(f\"  Network Density: {data['density']:.3f}\")\n",
    "            print(f\"  Average Clustering: {data['avg_clustering']:.3f}\")\n",
    "            \n",
    "            if data['top_central_substances']:\n",
    "                print(f\"  Most Central Substances:\")\n",
    "                for substance, centrality in data['top_central_substances'][:5]:\n",
    "                    print(f\"    - {substance}: {centrality:.3f}\")\n",
    "        else:\n",
    "            print(f\"  Unique Substances: {data['unique_substances']}\")\n",
    "            print(f\"  Co-occurrence Pairs: {data['cooccurrence_pairs']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 NPS Diffusion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = network_analyzer.analyze_nps_diffusion()\n",
    "\n",
    "print(\"NPS Diffusion Patterns:\\n\")\n",
    "for service_type, data in diffusion.items():\n",
    "    print(f\"{service_type}:\")\n",
    "    print(f\"  Total NPS Types: {data['total_nps_types']}\")\n",
    "    print(f\"  Avg New NPS per Month: {data['avg_new_nps_per_month']:.2f}\")\n",
    "    if data['first_nps_detected']:\n",
    "        print(f\"  First Detection: {data['first_nps_detected']}\")\n",
    "    if data['latest_nps_detected']:\n",
    "        print(f\"  Latest Detection: {data['latest_nps_detected']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. AI Research Assistant\n",
    "\n",
    "### 7.1 Generate Research Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = ResearchAssistant(quantitative_data=quant_df, qualitative_data=qual_df)\n",
    "\n",
    "research_questions = assistant.generate_research_questions()\n",
    "\n",
    "print(\"AI-Generated Research Questions:\\n\")\n",
    "for category, questions in research_questions.items():\n",
    "    if questions:\n",
    "        print(f\"{category.replace('_', ' ').title()}:\")\n",
    "        for i, q in enumerate(questions[:3], 1):\n",
    "            print(f\"  {i}. {q}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Generate Hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = assistant.generate_hypotheses()\n",
    "\n",
    "print(\"Testable Hypotheses:\\n\")\n",
    "for h in hypotheses[:3]:\n",
    "    print(f\"{h['id']}: {h['hypothesis']}\")\n",
    "    print(f\"  Type: {h['type']}\")\n",
    "    print(f\"  Suggested tests: {', '.join(h['suggested_tests'])}\")\n",
    "    print(f\"  Implications: {h['implications']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights = assistant.extract_key_insights()\n",
    "\n",
    "print(\"Key Insights:\\n\")\n",
    "for category, insights_list in insights.items():\n",
    "    if insights_list:\n",
    "        print(f\"{category.replace('_', ' ').title()}:\")\n",
    "        for insight in insights_list[:2]:\n",
    "            print(f\"  â€¢ {insight['insight']}\")\n",
    "            if 'implication' in insight:\n",
    "                print(f\"    â†’ {insight['implication']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Policy Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = assistant.generate_policy_recommendations()\n",
    "\n",
    "print(\"Policy Recommendations:\\n\")\n",
    "for rec in recommendations[:3]:\n",
    "    print(f\"{rec['id']} [{rec['priority'].upper()}]: {rec['recommendation']}\")\n",
    "    print(f\"\\n  Rationale:\")\n",
    "    for r in rec['rationale'][:2]:\n",
    "        print(f\"    â€¢ {r}\")\n",
    "    print(f\"\\n  Expected Outcomes:\")\n",
    "    for outcome in rec['expected_outcomes'][:2]:\n",
    "        print(f\"    âœ“ {outcome}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save comprehensive research report\n",
    "report_path = '../outputs/ai_research_report.txt'\n",
    "assistant.export_research_report(report_path)\n",
    "\n",
    "print(f\"âœ“ Comprehensive research report saved to: {report_path}\")\n",
    "print(\"\\nReport includes:\")\n",
    "print(\"  - Research questions\")\n",
    "print(\"  - Testable hypotheses\")\n",
    "print(\"  - Key insights\")\n",
    "print(\"  - Policy recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated the complete AI-driven research pipeline for analyzing drug checking services:\n",
    "\n",
    "1. **Quantitative Analysis**: Statistical comparisons, diversity indices, early warning indicators\n",
    "2. **AI-Powered NLP**: Sentiment analysis, topic modeling, named entity recognition\n",
    "3. **Machine Learning**: Trend forecasting, anomaly detection, substance clustering\n",
    "4. **Network Analysis**: Co-occurrence patterns, NPS diffusion, temporal evolution\n",
    "5. **Research Assistant**: Automated hypothesis generation, insight extraction, policy recommendations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "- Fixed-site services show higher substance diversity and NPS detection rates\n",
    "- Different service models serve complementary roles in harm reduction\n",
    "- AI analysis reveals hidden patterns in qualitative data\n",
    "- Predictive models enable proactive public health responses\n",
    "- Network analysis illuminates drug market dynamics\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Integrate with real-world data\n",
    "- Implement real-time monitoring dashboards\n",
    "- Develop automated alert systems\n",
    "- Expand predictive modeling capabilities\n",
    "- Conduct longitudinal studies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
